{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42381e2d",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup and Imports\n",
    "\n",
    "First, let's import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89115ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\n",
      "Scikit-learn version: 1.2.2\n",
      "Scikit-learn version: 1.2.2\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version}\")\n",
    "assert sys.version_info >= (3, 7), \"Python 3.7 or above is required\"\n",
    "\n",
    "# Scikit-learn imports\n",
    "import sklearn\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "\n",
    "# Set plot defaults\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6120892",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Load and Explore the Data\n",
    "\n",
    "### 2.1 Load the Dataset\n",
    "\n",
    "üìù **Your Task:** Load the CSV file containing the transcription data.\n",
    "\n",
    "üí° **Hint:** Use `pd.read_csv()` to load the data from `Data_AUG_13.11.2024_output.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dataset\n",
    "# data = pd.read_csv(___)\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ca9ef",
   "metadata": {},
   "source": [
    "### 2.2 Take a Quick Look at the Data Structure\n",
    "\n",
    "üìù **Your Task:** Explore the basic structure of the data:\n",
    "1. Display the first few rows\n",
    "2. Check the data types and non-null counts\n",
    "3. Get statistical summary\n",
    "\n",
    "üí° **Hint:** Use `.head()`, `.info()`, and `.describe()` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the first 5 rows\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd38cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check data types and missing values\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e045812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get statistical summary of numerical columns\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c2e411",
   "metadata": {},
   "source": [
    "### 2.3 Understand the Target Variable\n",
    "\n",
    "üìù **Your Task:** Explore the target variable `Class_label`:\n",
    "1. Check the unique values\n",
    "2. Check the class distribution (value counts)\n",
    "3. Visualize the class distribution\n",
    "\n",
    "üí° **Hint:** Use `.value_counts()` and `.plot.bar()`\n",
    "\n",
    "ü§î **Think About:** Is this a balanced or imbalanced dataset? How might this affect your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c52cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check the distribution of the target variable (Class_label)\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d675b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the class distribution with a bar plot\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8d881",
   "metadata": {},
   "source": [
    "### 2.4 Explore the Features\n",
    "\n",
    "üìù **Your Task:** Identify which columns are:\n",
    "- **Numerical features** (can be used directly)\n",
    "- **Categorical features** (may need encoding)\n",
    "- **Text columns** (transcriptions - may need special processing)\n",
    "- **ID/metadata columns** (should be excluded from training)\n",
    "\n",
    "üí° **Hint:** Look at columns like `token_count`, `type_token_ratio`, `filler_count`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ef4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: List all column names\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify numerical columns that could be good features\n",
    "# Hint: Columns like 'filler_count', 'token_count', 'type_count', \n",
    "# 'type_token_ratio', 'content_density', 'sentence_count', etc.\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f39d7",
   "metadata": {},
   "source": [
    "### 2.5 Visualize Feature Distributions\n",
    "\n",
    "üìù **Your Task:** Create histograms for the numerical features.\n",
    "\n",
    "üí° **Hint:** Use `df[numerical_columns].hist()` like we did in Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create histograms for numerical features\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56c3eb",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Data Preparation\n",
    "\n",
    "### 3.1 Select Features for Classification\n",
    "\n",
    "üìù **Your Task:** Select the features you want to use for classification.\n",
    "\n",
    "Consider using these numerical features:\n",
    "- `filler_count` - Number of filler words (um, uh, etc.)\n",
    "- `token_count` - Total number of words\n",
    "- `type_count` - Number of unique words\n",
    "- `type_token_ratio` - Vocabulary diversity measure\n",
    "- `content_density` - Content word ratio\n",
    "- `sentence_count` - Number of sentences\n",
    "- `average_words_per_sentence` - Sentence complexity\n",
    "- `Age` - Patient age\n",
    "- `Converted-MMSE` - Cognitive assessment score\n",
    "\n",
    "üí° **Hint:** Create a list of feature column names and extract them into X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your feature columns\n",
    "# feature_columns = [___]\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create X (features) and y (target)\n",
    "# X = data[feature_columns]\n",
    "# y = data['Class_label']\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35917c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check the shapes of X and y\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992808bb",
   "metadata": {},
   "source": [
    "### 3.2 Handle Missing Values\n",
    "\n",
    "üìù **Your Task:** Check for and handle missing values in your features.\n",
    "\n",
    "üí° **Hint:** Use `.isnull().sum()` to check, and consider using `.fillna()` or `SimpleImputer` from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for missing values in X\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle missing values if any exist\n",
    "# Option 1: Fill with median\n",
    "# X = X.fillna(X.median())\n",
    "\n",
    "# Option 2: Use SimpleImputer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# X = imputer.fit_transform(X)\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8921ed",
   "metadata": {},
   "source": [
    "### 3.3 Create Train/Test Split\n",
    "\n",
    "üìù **Your Task:** Split the data into training and test sets.\n",
    "\n",
    "‚ö†Ô∏è **Important:** Use **stratified sampling** to maintain class proportions!\n",
    "\n",
    "üí° **Hint:** Use `train_test_split()` with `stratify=y` parameter (like in Chapter 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Split the data with stratification\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaafc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Verify the split - check shapes and class distribution in both sets\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497b9cef",
   "metadata": {},
   "source": [
    "### 3.4 Feature Scaling\n",
    "\n",
    "üìù **Your Task:** Scale the features using StandardScaler.\n",
    "\n",
    "‚ö†Ô∏è **Important:** \n",
    "- Fit the scaler on training data only!\n",
    "- Transform both training and test data with the same scaler\n",
    "\n",
    "üí° **Hint:** Use `StandardScaler` from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Create scaler, fit on training data, transform both sets\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa81b8",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Training Binary Classifiers\n",
    "\n",
    "Now let's train some classifiers! Remember from Chapter 3, we can use various algorithms.\n",
    "\n",
    "### 4.1 Train an SGDClassifier\n",
    "\n",
    "üìù **Your Task:** Train an SGDClassifier on the training data.\n",
    "\n",
    "üí° **Hint:** Like in Chapter 3, use `SGDClassifier(random_state=42)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f641a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# TODO: Create and train the SGDClassifier\n",
    "# sgd_clf = SGDClassifier(random_state=42)\n",
    "# sgd_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c94c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions on a few samples from the test set\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c975a",
   "metadata": {},
   "source": [
    "### 4.2 Train a Random Forest Classifier\n",
    "\n",
    "üìù **Your Task:** Train a RandomForestClassifier.\n",
    "\n",
    "üí° **Hint:** Random Forests often perform well and can work without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: Create and train the RandomForestClassifier\n",
    "# forest_clf = RandomForestClassifier(random_state=42)\n",
    "# forest_clf.fit(X_train, y_train)  # Note: RF doesn't need scaled features\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321531b",
   "metadata": {},
   "source": [
    "### 4.3 (Optional) Try Other Classifiers\n",
    "\n",
    "üìù **Your Task:** Try at least one more classifier.\n",
    "\n",
    "Options to try:\n",
    "- `LogisticRegression`\n",
    "- `SVC` (Support Vector Classifier)\n",
    "- `KNeighborsClassifier`\n",
    "- you can be creative and try others too! or maybe somthing from hugging face like bert or distilbert for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try another classifier of your choice\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# log_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "# log_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d90ec3f",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance Evaluation\n",
    "\n",
    "### 5.1 Cross-Validation Accuracy\n",
    "\n",
    "üìù **Your Task:** Evaluate your classifiers using cross-validation.\n",
    "\n",
    "üí° **Hint:** Use `cross_val_score()` with `cv=5` (5-fold cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# TODO: Evaluate SGDClassifier with cross-validation\n",
    "# scores = cross_val_score(sgd_clf, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "# print(f\"SGD Accuracy: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate RandomForestClassifier with cross-validation\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518fe27",
   "metadata": {},
   "source": [
    "### 5.2 Confusion Matrix\n",
    "\n",
    "üìù **Your Task:** Generate and visualize the confusion matrix.\n",
    "\n",
    "üí° **Hint:** Use `cross_val_predict()` to get predictions, then `confusion_matrix()` or `ConfusionMatrixDisplay`\n",
    "\n",
    "ü§î **Think About:** What do the different quadrants mean?\n",
    "- True Positives (TP): Correctly predicted positive class\n",
    "- True Negatives (TN): Correctly predicted negative class\n",
    "- False Positives (FP): Incorrectly predicted as positive\n",
    "- False Negatives (FN): Incorrectly predicted as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce86467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# TODO: Get predictions using cross-validation\n",
    "# y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6800a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the confusion matrix\n",
    "# Option 1: Simple matrix\n",
    "# cm = confusion_matrix(y_train, y_train_pred)\n",
    "# print(cm)\n",
    "\n",
    "# Option 2: Visual display\n",
    "# ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "# plt.show()\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b32725",
   "metadata": {},
   "source": [
    "### 5.3 Precision, Recall, and F1-Score\n",
    "\n",
    "üìù **Your Task:** Calculate precision, recall, and F1-score for your classifiers.\n",
    "\n",
    "üí° **Hint:** Use `precision_score()`, `recall_score()`, and `f1_score()` from sklearn.metrics\n",
    "\n",
    "ü§î **Think About:**\n",
    "- **Precision** = TP / (TP + FP) - When we predict positive, how often are we correct?\n",
    "- **Recall** = TP / (TP + FN) - Of all actual positives, how many did we catch?\n",
    "- **F1** = Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13094c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# TODO: Calculate and print precision, recall, and F1 score\n",
    "# precision = precision_score(y_train, y_train_pred)\n",
    "# recall = recall_score(y_train, y_train_pred)\n",
    "# f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65017623",
   "metadata": {},
   "source": [
    "### 5.4 Precision-Recall Curve\n",
    "\n",
    "üìù **Your Task:** Plot the precision-recall curve.\n",
    "\n",
    "üí° **Hint:** \n",
    "1. Get decision scores using `cross_val_predict()` with `method='decision_function'` or `method='predict_proba'`\n",
    "2. Use `precision_recall_curve()` to compute the curve\n",
    "3. Plot precisions vs recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# TODO: Get decision scores (for classifiers that support it)\n",
    "# For SGDClassifier:\n",
    "# y_scores = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=5, method='decision_function')\n",
    "\n",
    "# For RandomForestClassifier (uses predict_proba):\n",
    "# y_probas = cross_val_predict(forest_clf, X_train, y_train, cv=5, method='predict_proba')\n",
    "# y_scores = y_probas[:, 1]  # Get probability of positive class\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d886f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute and plot the precision-recall curve\n",
    "# precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "# plt.plot(recalls, precisions)\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title('Precision-Recall Curve')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02188e5",
   "metadata": {},
   "source": [
    "### 5.5 ROC Curve and AUC\n",
    "\n",
    "üìù **Your Task:** Plot the ROC curve and calculate the AUC score.\n",
    "\n",
    "üí° **Hint:** Use `roc_curve()` and `roc_auc_score()` from sklearn.metrics\n",
    "\n",
    "ü§î **Think About:** \n",
    "- ROC shows True Positive Rate vs False Positive Rate\n",
    "- AUC of 0.5 = random classifier, AUC of 1.0 = perfect classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc264f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# TODO: Compute and plot the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "# \n",
    "# plt.figure(figsize=(6, 5))\n",
    "# plt.plot(fpr, tpr, linewidth=2, label='ROC Curve')\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate (Recall)')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f705b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the AUC score\n",
    "# auc = roc_auc_score(y_train, y_scores)\n",
    "# print(f\"AUC Score: {auc:.3f}\")\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2cc82a",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Final Evaluation on Test Set\n",
    "\n",
    "üìù **Your Task:** Choose your best model and evaluate it on the **held-out test set**.\n",
    "\n",
    "‚ö†Ô∏è **Important:** Only do this ONCE at the very end! The test set should remain untouched until final evaluation.\n",
    "\n",
    "üí° **Hint:** Use the same metrics you used before on the test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions on the test set with your best model\n",
    "# y_test_pred = best_clf.predict(X_test_scaled)  # or X_test for RF\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd646985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate all metrics on the test set\n",
    "# - Accuracy\n",
    "# - Precision\n",
    "# - Recall\n",
    "# - F1 Score\n",
    "# - AUC Score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8138b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print a complete classification report\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01bc99",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Error Analysis (Optional but Recommended)\n",
    "\n",
    "üìù **Your Task:** Analyze the errors your model makes.\n",
    "\n",
    "ü§î **Think About:**\n",
    "- Which samples are being misclassified?\n",
    "- Is there a pattern in the errors?\n",
    "- Which features might need more engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze misclassified samples\n",
    "# Hint: Find samples where y_train != y_train_pred and examine their features\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c5c58",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Feature Importance (Optional)\n",
    "\n",
    "üìù **Your Task:** If using Random Forest, examine feature importances.\n",
    "\n",
    "üí° **Hint:** Use `forest_clf.feature_importances_` to see which features matter most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee46640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot feature importances from Random Forest\n",
    "# importances = forest_clf.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.title(\"Feature Importances\")\n",
    "# plt.bar(range(len(importances)), importances[indices])\n",
    "# plt.xticks(range(len(importances)), [feature_columns[i] for i in indices], rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6b689",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Conclusions\n",
    "\n",
    "üìù **Your Task:** Write a brief summary of your findings:\n",
    "\n",
    "1. **Best Model:** Which classifier performed best?\n",
    "2. **Key Metrics:** What were the final precision, recall, and F1 scores?\n",
    "3. **Important Features:** Which features were most important for classification?\n",
    "4. **Challenges:** What challenges did you encounter?\n",
    "5. **Future Improvements:** What could be done to improve the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73d333",
   "metadata": {},
   "source": [
    "### Your Summary:\n",
    "\n",
    "*Write your conclusions here...*\n",
    "\n",
    "1. **Best Model:** \n",
    "\n",
    "2. **Key Metrics:**\n",
    "\n",
    "3. **Important Features:**\n",
    "\n",
    "4. **Challenges:**\n",
    "\n",
    "5. **Future Improvements:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
